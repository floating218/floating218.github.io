---
layout: post
title:  "스파크(1) : 아파치 하둡 소개"
date:   2020-01-06 13:36:15 +0900
categories: spark
permalink: '/spark/hadoop'
---

![hadoopeco](../assets/img/spark/hadoopeco.png) 


## 하둡

![hadoop](../assets/img/spark/hadoop.png) 


아파치 하둡이란 빅데이터를 저장, 처리, 분석할 수 있는 소프트웨어 프레임워크입니다. 구글은 빅데이터를 모아서 처리하기 위한 프레임워크의 필요성을 느끼게 되어 자체적으로 빅데이터 처리 프레임워크를 제작하였습니다. 한편 아파치 재단은 전세계에 프레임워크를 무료로 보급해야 한다는 필요성을 느꼈고, 그 필요에 의해 구글의 방식을 따라서 오픈 소스 형태로 비슷한 프레임워크를 만들어서 제공하게 됩니다. 이것이 하둡 프로젝트입니다. 


## 기존의 분산 처리 시스템의 문제점

기존의 분산 처리 시스템은 Message Passing Interface를 사용하였습니다. 여기에는 몇가지 문제가 있었는데요, 일단 ``프로그래밍이 매우 복잡``하였으며 여러 대의 컴퓨터 중 일부 컴퓨터가 고장하는 경우 전체 시스템이 동장하지 않는 ``partial failure``문제가 있었습니다. 

## 하둡에 도입된 새로운 분산 처리 시스템

2000년대 초반에 구글은 연구를 통해 자체적은 file system과 mapreduce 방법을 생각해냈습니다. 하둡은 아파치 재단에서 이 두가지 방법을 가져와서 만든 소프트웨어 프레임워크입니다. 하둡 분산 처리 시스템은 다음과 같은 특성이 있는데요

>1. 프로그래밍하기 비교적 쉽다.  
>2. 각 노드는 가급적 최소한의 데이터를 주고 받는다.   
>3. 데이터는 여러 노드에 미리 분산되어 저장하며, 저장된 위치에서 연산을 수행함.  

설명하자면, 데이터는 block으로 나누어져서, 파일 연산은 block단위로 이루어집니다. 하둡은 모든 연산을 ``mapreduce``방식으로 하는데요, 이 중에서 map task는 하나의 block단위로 작업이 처리됩니다. 

## 하둡의 구성요소 

하둡은 파일 시스템인 ``HDFS``와 스케줄링 시스템인 ``YARN`` 이렇게 두가지로 구성되어 있습니다. HDFS 클러스터와 YARN 클러스터가 서로 결합된 조합을 ``하둡 클러스터``라고 합니다.

## HDFS : 하둡 분산 파일 시스템

HDFS의 저장방식을 요약하면 다음과 같습니다. 
1. file은 block단위로 쪼갠다. 
2. 같은 file의 여러개의 block은 서로 다른 여러개의 노드에 저장된다. 
3. 이때 block은 여러개로 복제되어 서로 다른 노드에 저장된다. 기본적으로 3개씩 복제된다. 
4. name 노드 (= master 노드)가 존재한다. 이 노드는 file을 구성하는 block에 대한 정보와 그 block이 어디에 저장되어 있는지에 대한 정보를 관리한다. 이러한 정보를 meta data라고 한다. 

HDFS 파일 시스템의 구성요소
1. HDFS 클라이언트: name node를 통해 정보를 받아서 data 노드와 직접 통신을 합니다. 
2. Master노드(=Name 노드): slave 노드에 대한 정보와 task 관리를 합니다. 
3. Slave노드(=Data 노드): 실제로 데이터를 보유하며, client 요청을 받아서 데이터를 전달하거나 task를 수행합니다. 

## YARN https://www.popit.kr/what-is-hadoop-yarn/

하둡을 구성하는 두가지 컴포넌트 중 하나입니다. HDFS가 분산 파일 시스템이었다면, YARN은 분산 컴퓨팅 환경을 제공합니다. 

하둡이 처음 나왔을 때는 HDFS라는 파일 시스템과 전통적인 mapreduce라는 컴퓨팅 시스템을 사용하였습니다. YARN이 등장한 배경은 다음과 같은 기존 방식의 한계 때문이었습니다. 

> mapreduce 말고도 spark와 같은 다른 새로운 컴퓨팅 플랫폼을 사용하고 싶다. 
> 여러개의 컴퓨팅 플랫폼을 실행하면 리소스가 부족하다.

## MapReduce가 뭔데?  https://www.opentutorials.org/course/2908/17055

맵리듀스는 여러 노드에 task를 분배하는 방법입니다. 각 노드의 데이터는 각 노드에 저장되어 있습니다. 맵리듀스는 map과 reduce라는 두가지 단계로 구성됩니다. 다음과 같은 문제를 풀어야 한다고 가정해볼까요?

> "Welcome to Hadoop Class Hadoop is good Hadoop is bad" 이 문장에서 각 단어가 등장하는 빈도수를 세주세요

![MapReduce](../assets/img/spark/mapreduce.png) 


문장을 Input data로 받으면, 그 데이터를 각 노드에서 수행할 수 있도록 split 합니다. split 된 데이터를 가지고 mapper를 실행하면, 각 단어에 숫자 1을 붙이는 작업을 합니다. 이 결과를 shuffling하고 나서 reducer를 실행하면 최종 결과를 도출할 수 있게 됩니다. 

MapReduce 시스템은 다음과 같은 노드로 구성됩니다. 

![MapReduce System](../assets/img/spark/mapreduce2.png)

1. 맵리듀스 클라이언트: 데이터를 job의 형태로 jobtracker에 전달
2. Master노드(=jobtracker): 전체 job을 스케줄링하고 모니터링함.
3. Slave노드(=tasktracker): 사용자가 설정한 맵리듀스 프로그램을 실행하며, jobtracker로부터 작업을 요청받고, 맵 태스크와 리듀스 태스크를 생성합니다. 

## Mapper

하둡은 메타 데이터의 일부분을 노드에서 처리하게 함으로써 네트워크 트래픽을 방지합니다. Mapper는 Key/Value 형태로 데이터를 읽어서 다시 Key/Value 쌍 형태로 데이터를 출력해주는 작업을 합니다. Mapper의 결과는 중간 결과라고 할 수 있습니다. 

## Reducer

Mapper의 결과(중간 결과)는 각각 key값을 가지고 있었죠. 이제 공통의 key 값을 가진 결과끼리 리스트 형태로 조합됩니다. Reducer는 이렇게 조합된 key가 같은 데이터 리스트를 처리합니다. 

## YARN의 등장

기존에는 하둡 클러스터의 서버에서 리소스 상태는 jobtracker에 의해 관리되었습니다. 이는 다른 컴퓨팅 클러스터와 연동하기 어려웠습니다. YARN은 이 문제를 극복하기 위해 리소스 관리 파트만 가져와서 다른 서비스와 연동 가능하게 구현한 시스템입니다. 

YARN의 구성 요소는 다음과 같습니다. 
1. 리소스 매니저: YARN 클러스터에서의 master 서버이다. 
2. 노드 매니저: YARN 클러스터의 worker 서버이다. 

YARN은 혼자서는 아무것도 못합니다. MapReduce나 Spark와 같은 분산 컴퓨팅 플랫폼이 있어야 기능을 합니다. 


---
- HDFS: 클러스터 내에는 여러개의 노드가 있다. 각 노드에 파일이 분산되어 있는 블록으로 구성된 가상 파일시스템이다. 
- Ingestion 프로세스: 파일시스템에 데이터를 업로드할 때 블록의 크기에 맞게 무작위로 파일을 나눈다. 
- 클러스터 노드 간에 블록을 분산, 복제한다. 
- 메타데이터: 관련 정보(파일시스템, 가상 디렉토리, 물리적 블록에 대한 정보 등)는 메타데이터에 저장된다. 메타데이터는 NameNode라는 HDFS 마스터 노드의 상주 메모리에 저장된다. 
- NameNode: 메타데이터를 저장하며, HDFS 클라이언트에 read, write을 위한 블록 위치를 제공해줍니다.
- HDFS 클라이언트: DataNode와 직접 통신한다. 
- (그림)
- HDFS 읽기 작업의 예: 클라이언트가 네임노드에 파일 읽기를 요청하면, 네임노드가 메타 데이터에 포함된 정보를 준다. 이 정보는 요청한 파일의 블록이 포함된 데이터 노드의 목록이다. 정보를 받은 클라이언트는 받은 데이터 노드에 대해 데이터 블록을 검색해서 받는다. 
- (그림)
- HDFS 쓰기 작업의 예: 클라이언트가 네임노드에 파일 쓰기를 요청하면, 네임노드가 데이터노드 목록을 클라이언트에 전달한다. 그리고 클라이언트가 블록의 첫번째 복제본을 지정된 데이터 노드에 쓴다. 데이터 노드는 데이터 노드 사이의 복제 파이프라인을 만들어 클라이언트에 알린다. 블록 보고서는 데이터노드에서 네임노드로 정기적으로 전송된다.


    - ``HDFS``(하둡 분산 파일 시스템, hadoop distributed file system): 하둡의 스토리지 서브 시스템. 
    - ``YARN``(yet another resource regotiator): 하둡의 프로세싱 또는 리소스 스케줄링 서브시스템
    - 하둡클러스터: HDFS 클러스터와 YARN 클러스터가 서로 결합된 조합을 하둡클러스터라고 한다. 




## Apache Hadoop 프로젝트란

### 빅데이터와 하둡의 역사

- 맵리듀스: 2004년에 구글은 맵리듀스라는 논문을 발표했다. 
- 하둡: 구글의 논문에 영감을 받은 더그 커팅이 저장 및 처리 원칙을 통합해서 만든 것이 하둡이다. 하둡은 2006년에 아파치 재단에 등재되었다.
- 아파치 재단: 1999년에 설립된 재단으로서, 참가 개발자에게 오픈 소스 소프트웨어 구조 및 프레임 워크를 제공하기 위해 설립되었다. 

### 맵리듀스란? 

- 구글이 2003년에 ``구글 파일 시스템``이라는 논문을 발표함.
- 구글은 2004년에는 ``맵리듀스:대형 클러스터에서의 단순화된 데이터 처리``라는 논문을 발표함.
- 검색 엔진에서 방대한 양의 텍스트 데이터의 접근 방식에 대해 설명한 논문이라고 할 수 있다. 


### 하둡이란?

- ``하둡``: 데이터 지역성이라는 개념에 바탕을 둔 데이터 저장 및 처리 플랫폼.
- 데이터 지역성: 기존의 방식에서는 데이터를 원격 처리 시스템이나 호스트로 보내 처리한다. 그러나 데이터 지역성을 가진 데이터 처리 방식은, 데이터가 있는 곳으로 직접 이동해서 계산하는 방식이다. 
- 기존 방식의 어려움: 빅데이터의 겨우, 거대한 양의 데이터를 보내서 계산하고 처리하려면, 네트워크를 통해 데이터를 이동시키는 것이 비효율적이거나 비실용적일 수 있다. 
- 하둡의 장점: 비공유 접근을 사용하는 ``클러스터``의 ``노드``에서 데이터를 지역적으로 처리할 수 있다. 각 노드는 다른 노드와 데이터 통신할 필요가 없이 전체 데이터의 일부분만을 대상으로 독립적으로 처리를 수행한다. 이를 가능하게 하는 것은 분산 파일 시스템이다. 
    - ``클러스터``란?: 연산이나 프로세싱 함수를 수행하기 위해 함께 작동하는 시스템의 모음이다.
    - ``노드``란?: 클러스터 내의 개별 서버를 지칭함.
- Schema-on-read시스템: 하둡에는 정해진 스키마가 없다. 다시 말해, JSON, XML, RDB 등 다양한 비구조화 및 구조화 포맷의 문서에 대해 저장하고 처리할 수 있다. Schema-on-write시스템과 대조되는 시스템이다. 
- 하둡이 하는 일 : 큰 문제를 작은 문제의 집합으로 나누고 정리하며 데이터 지역성과 비공유 개념을 적용한다. 
- 하둡의 구성요소
    - ``HDFS``(하둡 분산 파일 시스템, hadoop distributed file system): 하둡의 스토리지 서브 시스템. 
    - ``YARN``(yet another resource regotiator): 하둡의 프로세싱 또는 리소스 스케줄링 서브시스템
    - 하둡클러스터: HDFS 클러스터와 YARN 클러스터가 서로 결합된 조합을 하둡클러스터라고 한다. 

### HDFS

- HDFS: 클러스터 내에는 여러개의 노드가 있다. 각 노드에 파일이 분산되어 있는 블록으로 구성된 가상 파일시스템이다. 
- Ingestion 프로세스: 파일시스템에 데이터를 업로드할 때 블록의 크기에 맞게 무작위로 파일을 나눈다. 
- 클러스터 노드 간에 블록을 분산, 복제한다. 
- 메타데이터: 관련 정보(파일시스템, 가상 디렉토리, 물리적 블록에 대한 정보 등)는 메타데이터에 저장된다. 메타데이터는 NameNode라는 HDFS 마스터 노드의 상주 메모리에 저장된다. 
- NameNode: 메타데이터를 저장하며, HDFS 클라이언트에 read, write을 위한 블록 위치를 제공해줍니다.
- HDFS 클라이언트: DataNode와 직접 통신한다. 
- (그림)
- HDFS 읽기 작업의 예: 클라이언트가 네임노드에 파일 읽기를 요청하면, 네임노드가 메타 데이터에 포함된 정보를 준다. 이 정보는 요청한 파일의 블록이 포함된 데이터 노드의 목록이다. 정보를 받은 클라이언트는 받은 데이터 노드에 대해 데이터 블록을 검색해서 받는다. 
- (그림)
- HDFS 쓰기 작업의 예: 클라이언트가 네임노드에 파일 쓰기를 요청하면, 네임노드가 데이터노드 목록을 클라이언트에 전달한다. 그리고 클라이언트가 블록의 첫번째 복제본을 지정된 데이터 노드에 쓴다. 데이터 노드는 데이터 노드 사이의 복제 파이프라인을 만들어 클라이언트에 알린다. 블록 보고서는 데이터노드에서 네임노드로 정기적으로 전송된다. 

### YARN

- YARN: YARN은 하둡의 데이터 처리를 제어하고 조율한다. 
- 스파크 응용 프로그램에서 가장 일반적으로 사용되는 ``프로세스 스케줄러``라고 보면 된다. 
- 리소스란?: CPU코어와 메모리의 조합(단위:컨테이너)

    - 리소스 매니저: 
        - 클라이언트로부터 응용프로그램(예를 들어 스파크)을 받고
        - 노드 매니저에게 애플리케이션 마스터 프로세스를 할당함
    - 애플리케이선 마스터(AM): 응용 프로그램.
        - 노드 매니저에게 프로세스를 전달한다.
    - 노드 매니저들
        - 작업 시도 상태와 진행 상황을 애플리케이션 마스터에게 보고함. 

### Spark

- 아파치 스파크 프로젝트: 2009년에 시작한 오픈소스 분산 데이터 처리 프로젝트이다.
- 목적은 맵리듀스를 대체할 수 있는 리소스 스케줄링 및 오케스트레이션 시스템을 검토하도록 설계되었음. 
- 스파크는 맵리두스에 비해 RDD를 사용함. RDD는 다음 특성이 있음
    - 분산형
    - 내결함성 fault-tolerant
    - 인메모리 in-memory: 인메모리 구조를 재사용하여 메모리 사용을 극대화함. 
- 스파크는 자바 가상 머신 (JVM)과 Scala로 작성되었음. 

### 스파크가 지원하는 응용 프로그램들

- 스파크가 지원하는 다양한 응용 프로그램들
    - 머신러닝(예측 분석)
    - SQL 쿼리, 시각화
    - 텍스트 마이닝
    - 추천엔진, 패턴인식 등

### 스파크의 프로그래밍 인터페이스

- 스파크는 본래 scala로 작성되어 jvm에서 실행되나
- 다양한 프로그래밍 인터페이스를 지원한다.
    - scala, python, java, sql , r 등

### 스파크 RDD

- 스파크 RDD: 스파크 응용 프로그램의 기본 데이터 추상화 구조이다.
- 클러스터에 분산된 인 메모리 데이터 모음이라고 할 수 있음. 

### 요약

- 하둡: 그냥 hdfs와 일치하는 개념으로 주로 쓰인다. 스파크는 hdfs에서 파일을 읽고 hdfs로 파일을 쓴다. 
- YARN: 프로세스 스케줄러이자 리소스 스케줄러. 스파크의 응용 프로그램이라고 할 수 있다. YARN은 일반적으로 하둡의 hdfs와 함께 있다. 스파크의 처리를 병렬로 실행할 수 있도록 하둡 클러스터의 분산 노드 내에서 리소스를 관리해준다. 


---

### Reference
- <a href="#"> 파이썬을 활용한 스파크 프로그래밍 - 제프리 에이븐 </a>