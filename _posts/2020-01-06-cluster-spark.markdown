---
layout: post
title:  "스파크 클러스터 아키텍쳐"
date:   2020-01-16 16:36:15 +0900
categories: spark
permalink: '/spark/cluster-spark'
---

--- 
## Apache Hadoop 프로젝트란

### 빅데이터와 하둡의 역사

- 맵리듀스: 2004년에 구글은 맵리듀스라는 논문을 발표했다. 
- 하둡: 구글의 논문에 영감을 받은 더그 커팅이 저장 및 처리 원칙을 통합해서 만든 것이 하둡이다. 하둡은 2006년에 아파치 재단에 등재되었다.
- 아파치 재단: 1999년에 설립된 재단으로서, 참가 개발자에게 오픈 소스 소프트웨어 구조 및 프레임 워크를 제공하기 위해 설립되었다. 

### 맵리듀스란? 

- 구글이 2003년에 ``구글 파일 시스템``이라는 논문을 발표함.
- 구글은 2004년에는 ``맵리듀스:대형 클러스터에서의 단순화된 데이터 처리``라는 논문을 발표함.
- 검색 엔진에서 방대한 양의 텍스트 데이터의 접근 방식에 대해 설명한 논문이라고 할 수 있다. 


### 하둡이란?

- ``하둡``: 데이터 지역성이라는 개념에 바탕을 둔 데이터 저장 및 처리 플랫폼.
- 데이터 지역성: 기존의 방식에서는 데이터를 원격 처리 시스템이나 호스트로 보내 처리한다. 그러나 데이터 지역성을 가진 데이터 처리 방식은, 데이터가 있는 곳으로 직접 이동해서 계산하는 방식이다. 
- 기존 방식의 어려움: 빅데이터의 겨우, 거대한 양의 데이터를 보내서 계산하고 처리하려면, 네트워크를 통해 데이터를 이동시키는 것이 비효율적이거나 비실용적일 수 있다. 
- 하둡의 장점: 비공유 접근을 사용하는 ``클러스터``의 ``노드``에서 데이터를 지역적으로 처리할 수 있다. 각 노드는 다른 노드와 데이터 통신할 필요가 없이 전체 데이터의 일부분만을 대상으로 독립적으로 처리를 수행한다. 이를 가능하게 하는 것은 분산 파일 시스템이다. 
    - ``클러스터``란?: 연산이나 프로세싱 함수를 수행하기 위해 함께 작동하는 시스템의 모음이다.
    - ``노드``란?: 클러스터 내의 개별 서버를 지칭함.
- Schema-on-read시스템: 하둡에는 정해진 스키마가 없다. 다시 말해, JSON, XML, RDB 등 다양한 비구조화 및 구조화 포맷의 문서에 대해 저장하고 처리할 수 있다. Schema-on-write시스템과 대조되는 시스템이다. 
- 하둡이 하는 일 : 큰 문제를 작은 문제의 집합으로 나누고 정리하며 데이터 지역성과 비공유 개념을 적용한다. 
- 하둡의 구성요소
    - ``HDFS``(하둡 분산 파일 시스템, hadoop distributed file system): 하둡의 스토리지 서브 시스템. 
    - ``YARN``(yet another resource regotiator): 하둡의 프로세싱 또는 리소스 스케줄링 서브시스템
    - 하둡클러스터: HDFS 클러스터와 YARN 클러스터가 서로 결합된 조합을 하둡클러스터라고 한다. 

### HDFS

- HDFS: 클러스터 내에는 여러개의 노드가 있다. 각 노드에 파일이 분산되어 있는 블록으로 구성된 가상 파일시스템이다. 
- Ingestion 프로세스: 파일시스템에 데이터를 업로드할 때 블록의 크기에 맞게 무작위로 파일을 나눈다. 
- 클러스터 노드 간에 블록을 분산, 복제한다. 
- 메타데이터: 관련 정보(파일시스템, 가상 디렉토리, 물리적 블록에 대한 정보 등)는 메타데이터에 저장된다. 메타데이터는 NameNode라는 HDFS 마스터 노드의 상주 메모리에 저장된다. 
- NameNode: 메타데이터를 저장하며, HDFS 클라이언트에 read, write을 위한 블록 위치를 제공해줍니다.
- HDFS 클라이언트: DataNode와 직접 통신한다. 
- (그림)
- HDFS 읽기 작업의 예: 클라이언트가 네임노드에 파일 읽기를 요청하면, 네임노드가 메타 데이터에 포함된 정보를 준다. 이 정보는 요청한 파일의 블록이 포함된 데이터 노드의 목록이다. 정보를 받은 클라이언트는 받은 데이터 노드에 대해 데이터 블록을 검색해서 받는다. 
- (그림)
- HDFS 쓰기 작업의 예: 클라이언트가 네임노드에 파일 쓰기를 요청하면, 네임노드가 데이터노드 목록을 클라이언트에 전달한다. 그리고 클라이언트가 블록의 첫번째 복제본을 지정된 데이터 노드에 쓴다. 데이터 노드는 데이터 노드 사이의 복제 파이프라인을 만들어 클라이언트에 알린다. 블록 보고서는 데이터노드에서 네임노드로 정기적으로 전송된다. 

### YARN

- YARN: YARN은 하둡의 데이터 처리를 제어하고 조율한다. 
- 스파크 응용 프로그램에서 가장 일반적으로 사용되는 ``프로세스 스케줄러``라고 보면 된다. 
- 리소스란?: CPU코어와 메모리의 조합(단위:컨테이너)

    - 리소스 매니저: 
        - 클라이언트로부터 응용프로그램(예를 들어 스파크)을 받고
        - 노드 매니저에게 애플리케이션 마스터 프로세스를 할당함
    - 애플리케이선 마스터(AM): 응용 프로그램.
        - 노드 매니저에게 프로세스를 전달한다.
    - 노드 매니저들
        - 작업 시도 상태와 진행 상황을 애플리케이션 마스터에게 보고함. 

### Spark

- 아파치 스파크 프로젝트: 2009년에 시작한 오픈소스 분산 데이터 처리 프로젝트이다.
- 목적은 맵리듀스를 대체할 수 있는 리소스 스케줄링 및 오케스트레이션 시스템을 검토하도록 설계되었음. 
- 스파크는 맵리두스에 비해 RDD를 사용함. RDD는 다음 특성이 있음
    - 분산형
    - 내결함성 fault-tolerant
    - 인메모리 in-memory: 인메모리 구조를 재사용하여 메모리 사용을 극대화함. 
- 스파크는 자바 가상 머신 (JVM)과 Scala로 작성되었음. 

### 스파크가 지원하는 응용 프로그램들

- 스파크가 지원하는 다양한 응용 프로그램들
    - 머신러닝(예측 분석)
    - SQL 쿼리, 시각화
    - 텍스트 마이닝
    - 추천엔진, 패턴인식 등

### 스파크의 프로그래밍 인터페이스

- 스파크는 본래 scala로 작성되어 jvm에서 실행되나
- 다양한 프로그래밍 인터페이스를 지원한다.
    - scala, python, java, sql , r 등

### 스파크 RDD

- 스파크 RDD: 스파크 응용 프로그램의 기본 데이터 추상화 구조이다.
- 클러스터에 분산된 인 메모리 데이터 모음이라고 할 수 있음. 

### 요약

- 하둡: 그냥 hdfs와 일치하는 개념으로 주로 쓰인다. 스파크는 hdfs에서 파일을 읽고 hdfs로 파일을 쓴다. 
- YARN: 프로세스 스케줄러이자 리소스 스케줄러. 스파크의 응용 프로그램이라고 할 수 있다. YARN은 일반적으로 하둡의 hdfs와 함께 있다. 스파크의 처리를 병렬로 실행할 수 있도록 하둡 클러스터의 분산 노드 내에서 리소스를 관리해준다. 


---

### Reference
- <a href="#"> 참고사이트 </a>